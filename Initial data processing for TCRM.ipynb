{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial data processing for TCRM\n",
    "\n",
    "Before we simulate synthetic TC events, we need to perform some basic processing of the input TC observation database. There's a significant amount of inconsistency and missing data in the best-track archives, and so we need to separate out the required data and ensure there is no invalid data in there. \n",
    "\n",
    "This notebook will execute the initial processing steps that TCRM uses, so that we can then use the resulting data in subsequent notebooks that explore in more detail the inner workings of TCRM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import os\n",
    "import io\n",
    "import sys\n",
    "\n",
    "from tcrm import doOutputDirectoryCreation\n",
    "from DataProcess.DataProcess import DataProcess\n",
    "from Utilities.config import ConfigParser\n",
    "from Utilities.parallel import attemptParallel, disableOnWorkers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because TCRM is often executed in a parallel processing environment, we need to have methods to ensure that some parts of the code only execute on a single processor, e.g. directory creation, to avoid race conditions and multiple processes attempting to read/write from one file. This next bit of code helps to handle that problem. You don't need to know the details of what's going on here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global pp\n",
    "pp = attemptParallel()\n",
    "import atexit\n",
    "atexit.register(pp.finalize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "configstr = \"\"\"\n",
    "[DataProcess]\n",
    "InputFile=/home/tcrm/tcrm/input/Allstorms.ibtracs_wmo.v03r09.csv\n",
    "Source=IBTRACS\n",
    "StartSeason=1981\n",
    "FilterSeasons=False\n",
    "\n",
    "[Region]\n",
    "; Domain for windfield and hazard calculation\n",
    "gridLimit={'xMin':90.,'xMax':180.,'yMin':-30.0,'yMax':-5.0}\n",
    "gridSpace={'x':1.0,'y':1.0}\n",
    "gridInc={'x':1.0,'y':0.5}\n",
    "\n",
    "[TrackGenerator]\n",
    "NumSimulations=5000\n",
    "YearsPerSimulation=10\n",
    "SeasonSeed=68876543\n",
    "TrackSeed=334825\n",
    "TimeStep=1.0\n",
    "\n",
    "[Input]\n",
    "landmask = /home/tcrm/tcrm/input/landmask.nc\n",
    "mslpfile = /home/tcrm/tcrm/MSLP/slp.day.ltm.nc\n",
    "datasets = IBTRACS,LTMSLP\n",
    "\n",
    "[Output]\n",
    "Path=/media/sf_share/tcrm/fiji\n",
    "\n",
    "[Hazard]\n",
    "Years=2,5,10,20,25,50,100,200,250,500,1000,2000,2500,5000\n",
    "MinimumRecords=10\n",
    "CalculateCI=False\n",
    "\n",
    "[Logging]\n",
    "LogFile=/media/sf_share/tcrm/fiji/log/fiji.log\n",
    "LogLevel=INFO\n",
    "Verbose=False\n",
    "\n",
    "[IBTRACS]\n",
    "; Input data file settings\n",
    "url = ftp://eclipse.ncdc.noaa.gov/pub/ibtracs/v03r06/wmo/csv/Allstorms.ibtracs_wmo.v03r09.csv.gz\n",
    "path = /home/tcrm/tcrm/input/\n",
    "filename = Allstorms.ibtracs_wmo.v03r09.csv\n",
    "columns = tcserialno,season,num,skip,skip,skip,date,skip,lat,lon,skip,pressure\n",
    "fielddelimiter = ,\n",
    "numberofheadinglines = 3\n",
    "pressureunits = hPa\n",
    "lengthunits = km\n",
    "dateformat = %Y-%m-%d %H:%M:%S\n",
    "speedunits = kph\n",
    "\n",
    "[LTMSLP]\n",
    "; MSLP climatology file settings\n",
    "URL = ftp://ftp.cdc.noaa.gov/Datasets/ncep.reanalysis.derived/surface/slp.day.1981-2010.ltm.nc\n",
    "path = /home/tcrm/tcrm/MSLP\n",
    "filename = slp.day.ltm.nc\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following piece of code sets up an instance of Python's `ConfigParser` configuration module, with a couple of minor modifications for TCRM. We then read in the string version of the configuration detailed above. We could equally pass the `config.readfp()` method the name of a complete TCRM configuration file, but it's easier to show how configuration changes affect the way the model operates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = ConfigParser()\n",
    "config.readfp(io.BytesIO(configstr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to create a directory for the output to be stored in. If the specified directory already exists, the data that exists in that folder will be overwritten. If the output directory cannot be created, either due to permission errors or because you've specified a path that is unreachable, then the code will raise an exception, indicating the reason for the failure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doOutputDirectoryCreation(configstr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These two lines do the majority of the work of processing the input file. The first sets up a `DataProcess` object, which has a single public method (but many private methods) to perform the processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp = DataProcess(configstr)\n",
    "dp.processData()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You might see a couple of \"WARNING\" messages appear indicating that certain data fields are not available. These are optional, not essential fields. If essential fields are missing, then the `processData` method will raise an exception and stop execution.\n",
    "\n",
    "So now, what has this produced? We can check the files that now exist in the output path:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputPath = config.get('Output', 'Path')\n",
    "processPath = os.path.join(outputPath, 'process')\n",
    "dirlist = [f for f in os.listdir(processPath) if os.path.isfile(os.path.join(processPath, f))]\n",
    "dirlist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The listing shows a number of files, with no extension. These are text files, some in a csv format, that are read by different processes at different stages later in the execution of TCRM. \n",
    "\n",
    "#### Questions:\n",
    "1. Open the 'cyclone_tracks' file in a text editor and check out the contents. What might the first column represent? What about the other columns?\n",
    "2. Open the 'jday_genesis' file and see if you can dduce what it contains.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting the output from `DataProcess`\n",
    "\n",
    "To let you visually inspect the data produced by `DataProcess.processData`, there's a simple function that plots the data for you. We'll execute the function here, then display the contents in the notebook, using some simple IPython functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tcrm import doDataPlotting\n",
    "from ipywidgets import interact, Dropdown\n",
    "from IPython.display import Image, display\n",
    "\n",
    "doDataPlotting(configstr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statsPlotPath = os.path.join(outputPath, 'plots/stats')\n",
    "imglist = os.listdir(statsPlotPath)\n",
    "\n",
    "def showImg(imgfile):\n",
    "    x = Image(os.path.join(statsPlotPath, imgfile))\n",
    "    display(x)\n",
    "    \n",
    "imgDropdown = Dropdown(options=imglist, value=imglist[0], description=\"File name\")\n",
    "interact(showImg, imgfile=imgDropdown)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Questions:\n",
    "\n",
    "1. Compare the figures for the 'pressure' and 'pressure_rate' results. The x-axis is the observations at one time, and the y-axis is the observation at the previous time step, essentially the autocorrelation. What can you say about the pressure variable? What about the pressure rate of change? \n",
    "\n",
    "2. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistical processing \n",
    "\n",
    "We now move on to the step of calculating the gridded statistics across the domain. In this step, we calculate the mean, variances and lag-1 autocorrelations for all the key variables that we use in generating synthetic tracks.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from DataProcess.CalcTrackDomain import CalcTrackDomain\n",
    "from StatInterface import StatInterface"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we calculate the domain of the tracks that enter the region that we want to cover in our simulation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CalcTD = CalcTrackDomain(configstr)\n",
    "trackDomain = CalcTD.calcDomainFromFile()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First see what this means. The configuration has defined a region for which we want to run the model. But there are TC tracks that enter this region which start outside the region. If we were to exclude those events, we would underestimate the frequency of events, as well as have an incomplete record of the behavoiur of cyclones in the domain. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to add the historical tracks:\n",
    "from Utilities.loadData import loadTrackFile\n",
    "\n",
    "trackFile = config.get('DataProcess', 'InputFile')\n",
    "source = config.get('DataProcess', 'Source')\n",
    "\n",
    "tracks = loadTrackFile(configstr, trackFile, source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mticker\n",
    "import cartopy.crs as ccrs\n",
    "from cartopy.mpl.gridliner import LONGITUDE_FORMATTER, LATITUDE_FORMATTER\n",
    "\n",
    "import shapely.geometry as sg\n",
    "gridLimit = eval(config.get('Region', 'gridLimit'))\n",
    "fig = plt.figure()\n",
    "\n",
    "prj = ccrs.PlateCarree(central_longitude=180)\n",
    "prj0 = ccrs.PlateCarree(central_longitude=0)\n",
    "ax = plt.axes(projection=prj)\n",
    "ax.set_extent([120, 200, -30, -5], prj0)       \n",
    "\n",
    "ax.coastlines(resolution='50m', color='black', linewidth=1)\n",
    "simBox = sg.box(minx=gridLimit['xMin'], maxx=gridLimit['xMax'],\n",
    "                   miny=gridLimit['yMin'], maxy=gridLimit['yMax'])\n",
    "trackBox = sg.box(minx=trackDomain['xMin'], maxx=trackDomain['xMax'],\n",
    "                     miny=trackDomain['yMin'], maxy=trackDomain['yMax'])\n",
    "\n",
    "for t in tracks:\n",
    "    if t.inRegion(trackDomain):\n",
    "        plt.plot(t.Longitude, t.Latitude, color='gray', linewidth=1, transform=prj0, alpha=0.25)\n",
    "        \n",
    "ax.add_geometries([simBox], prj0, facecolor='coral', \n",
    "                   edgecolor='black', alpha=0.5)\n",
    "ax.add_geometries([trackBox], prj0, facecolor='', \n",
    "                   edgecolor='blue', linewidth=2)\n",
    "ax.set_extent([120, 200, -30, -5], prj0)       \n",
    "gl = ax.gridlines(crs=prj0, draw_labels=True,\n",
    "                  linewidth=0.5, color='gray', alpha=0.5, linestyle='--')\n",
    "gl.xlabels_top = False\n",
    "gl.ylabels_left = False\n",
    "gl.xlocator = mticker.FixedLocator(range(120, 210, 15))\n",
    "gl.ylocator = mticker.FixedLocator(range(-30, 0, 5))\n",
    "\n",
    "gl.xformatter = LONGITUDE_FORMATTER\n",
    "gl.yformatter = LATITUDE_FORMATTER\n",
    "gl.xlabel_style = {'size': 10, 'color': 'black'}\n",
    "gl.ylabel_style = {'size': 10, 'color': 'black'}\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In red is the region we want the simulation to cover (the \"simulation domain\"). In grey are all the tracks that *enter* the red box. The blue box is the outer limit of the tracks that enter the simulation domain. We actually need to simulate tracks across the blue region (the \"track domain\"), to ensure we get an accurate representation of the TC activity in the simulation domain. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then use that new track domain to define the grid for which we will calculate the statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statInterface = StatInterface.StatInterface(configstr, autoCalc_gridLimit=trackDomain)\n",
    "statInterface.kdeOrigin()\n",
    "statInterface.kdeGenesisDate()\n",
    "statInterface.cdfCellBearing()\n",
    "statInterface.cdfCellSpeed()\n",
    "statInterface.cdfCellPressure()\n",
    "statInterface.calcCellStatistics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
